{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from DB import DB\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "from sortedcontainers import SortedListWithKey\n",
    "import statistics\n",
    "import requests\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from xml.etree import ElementTree\n",
    "from auth import AzureAuthClient\n",
    "import requests\n",
    "import pickle\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_collection(argv):\n",
    "    database = DB(argv[0], argv[1])\n",
    "    collection = database.get_collection(argv[2])\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results(collection, query, projection):\n",
    "    #cursor_it = collection.find(query,projection)\n",
    "    #cursor_it = collection.find()\n",
    "    cursor_it = collection.find({},{\"_id\":-1, \"id\":1, \"user.followers_count\":1,\"favorite_count\":1, \n",
    "                    \"retweet_count\":1, \"entities.hashtags\":1, \"text\":1,\n",
    "                               \"processed_text\":1, \"created_at\":1})\n",
    "    return list(cursor_it)\n",
    "'''\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analytics(cursor):\n",
    "    vocabulary = defaultdict(int)\n",
    "    top_retweeted = SortedListWithKey(key=lambda x: x[\"retweet_count\"])\n",
    "    top_fav = SortedListWithKey(key=lambda x: x[\"favorite_count\"])\n",
    "    top_followed = SortedListWithKey(key=lambda x: x[\"user\"]['followers_count'])\n",
    "    prices = []\n",
    "    \n",
    "    for tweet in cursor:\n",
    "        flag = False #look for prices\n",
    "        clues = [\"bearish\", \"bullish\",\"hold\",\"stock\",\"share\"]\n",
    "        intersection_1 = [word for word in tweet[\"processed_text\"] if word in clues]\n",
    "        # intersection_2 = [word for word in tweet[\"processed_text\"] if word in [\"â‚¬\", \"EUR\", 'eur']]\n",
    "    \n",
    "    \n",
    "        text = tweet[\"processed_text\"]\n",
    "    \n",
    "        if intersection_1:\n",
    "            if \"bmw\" in text:\n",
    "                flag = True\n",
    "                #print(tweet['text'])\n",
    "    \n",
    "        for word in tweet[\"processed_text\"]:\n",
    "            if flag:\n",
    "                try:\n",
    "                    number = float(word)\n",
    "                    if number < 100 and number > 50:\n",
    "                        prices.append(number)\n",
    "                except:\n",
    "                    pass\n",
    "         \n",
    "            vocabulary[word] += 1\n",
    "    \n",
    "        top_retweeted.add(tweet)\n",
    "        if len(top_retweeted) > 200:\n",
    "            top_retweeted.pop(0)\n",
    "\n",
    "        top_fav.add(tweet)\n",
    "        if len(top_fav) > 100:\n",
    "            top_fav.pop(0)\n",
    "                \n",
    "        top_followed.add(tweet)\n",
    "        if len(top_followed) > 100:\n",
    "            top_followed.pop(0)\n",
    "    \n",
    "    return vocabulary, top_retweeted, top_fav, top_followed, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_prices(prices):\n",
    "\n",
    "    prices.sort(reverse=True)\n",
    "    total = sum(prices)\n",
    "    print(\"Average price: {}\".format(total/len(prices)))\n",
    "    print(\"Lowest price: {}\".format(prices[0]))\n",
    "    print(\"Highest price: {}\".format(prices[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_german_tweets(cursor, collection):\n",
    "    stop_words = set(stopwords.words(\"german\"))\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,reduce_len=True,strip_handles=False)\n",
    "    punct = string.punctuation\n",
    "    punct_1 = punct.replace('#', '')\n",
    "    punct_2 = punct_1.replace('@', '')\n",
    "    stop_words.update(punct_2)\n",
    "    stop_words.add('...')\n",
    "    \n",
    "    for tweet in cursor:\n",
    "        if 'processed_text_de' not in tweet:\n",
    "            tokens = tokenizer.tokenize(tweet['text'])\n",
    "            filtered_tokens = [word for word in tokens if not word in stop_words]\n",
    "            filtered_no_url = [word for word in filtered_tokens if not 'http' in word]\n",
    "            collection.update_one({\"id\":tweet[\"id\"]}, \n",
    "                                { '$set': { 'processed_text_de': filtered_no_url}})\n",
    "            collection.update_one({\"id\":tweet[\"id\"]}, \n",
    "                                { '$unset': { 'processed_text': 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_tweet(text:str, language):\n",
    "    if language == 'en':\n",
    "        lang = 'english'\n",
    "    if language == 'de':\n",
    "        lang = 'german'\n",
    "\n",
    "    #Tokenize the tweet text\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,reduce_len=True,strip_handles=False)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    #remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punct = string.punctuation\n",
    "    punct_1 = punct.replace('#', '')\n",
    "    punct_2 = punct_1.replace('@', '')\n",
    "    stop_words.update(punct_2)\n",
    "    stop_words.add('...')\n",
    "\n",
    "    filtered_tokens = [word for word in tokens if not word in stop_words]\n",
    "    filtered_no_url = [word for word in filtered_tokens if not 'http' in word]\n",
    "\n",
    "    #stemming\n",
    "    if language == 'en':\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_tokens = [stemmer.stem(word) if (word[0] != '#' and word[0] != '@' ) else word for word in filtered_no_url]\n",
    "        return stemmed_tokens\n",
    "    if language == 'german':\n",
    "        return filtered_no_url\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(cursor, collection):\n",
    "    for tweet in cursor:\n",
    "        if tweet['text_en'] is not None:\n",
    "            processed_text = preprocess_tweet(tweet['text_en'], 'en')\n",
    "        else:\n",
    "            processed_text = \"\"\n",
    "        \n",
    "        collection.update_one({\"id\":tweet[\"id\"]}, \n",
    "                                { '$set': { 'processed_text': processed_text}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_translation(cursor,collection):\n",
    "    temp_list = []\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,reduce_len=True,strip_handles=False)\n",
    "    client_secret = 'db36d42fd17b43bbbacacbaf545e513c'\n",
    "    auth_client = AzureAuthClient(client_secret)\n",
    "    bearer_token = b'Bearer ' + auth_client.get_access_token()\n",
    "    finalToken = bearer_token\n",
    "    headers = {\"Authorization \": finalToken}\n",
    "    \n",
    "    for tweet in cursor:\n",
    "        tokens = tokenizer.tokenize(tweet['text'])\n",
    "        filtered_no_url = [word for word in tokens if not 'http' in word]\n",
    "        \n",
    "        text_to_translate = \" \".join(filtered_no_url)\n",
    "        \n",
    "        translateUrl = \"http://api.microsofttranslator.com/v2/Http.svc/Translate?text={}&to={}\".format(text_to_translate, 'en')\n",
    "        translationData = requests.get(translateUrl, headers = headers)\n",
    "        # parse xml return values\n",
    "        translation = ElementTree.fromstring(translationData.text.encode('utf-8'))\n",
    "        temp_list.append((tweet[\"id\"],translation))\n",
    "    \n",
    "    pickle.dump( temp_list, open( \"translations.p\", \"wb\" ) )\n",
    "    return temp_list\n",
    "                \n",
    "    #collection.update_one({\"id\":tweet[\"id\"]}, { '$set': { 'text_en': translation}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection = get_collection([\"mongodb://127.0.0.1:27017\",\"dax\", \"tweets_de\"])\n",
    "cursor = get_results(collection,{},{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary, top_retweeted, top_fav, top_followed, prices = analytics(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in reversed(top_fav):\n",
    "    pprint.pprint(item['text_en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in reversed(top_followed):\n",
    "    pprint.pprint(item['text_en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in top_retweeted:\n",
    "    pprint.pprint(item['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_vocabulary = sorted(vocabulary, key=vocabulary.__getitem__, reverse=True)\n",
    "for i in range(0,41):\n",
    "    print(\"{},{}\".format(sorted_vocabulary[i], vocabulary[sorted_vocabulary[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in vocabulary.keys():\n",
    "    if key == 'recal':\n",
    "        print(\"Recall\",vocabulary[key])\n",
    "    if key == 'sale':\n",
    "        print('Sales',vocabulary[key])\n",
    "    if key == 'financi':\n",
    "        print('Financial',vocabulary[key])\n",
    "    if key == 'bearish':\n",
    "        print('Bearish',vocabulary[key])\n",
    "    if key == 'Bullish':\n",
    "        print('Bullish',vocabulary[key])\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in cursor:\n",
    "    tweet['date'] = datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S %z %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.sort(key=lambda d: d['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-18 08:37:50+00:00\n",
      "2017-08-01 15:36:20+00:00\n"
     ]
    }
   ],
   "source": [
    "print(cursor[0]['date'])\n",
    "print(cursor[-1][\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}